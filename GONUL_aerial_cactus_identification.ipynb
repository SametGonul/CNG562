{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['aerial-cactus-identification', 'resnett']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import optimizers\n\n","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size = (3,3), input_shape = (150, 150, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(32, kernel_size = (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(64, kernel_size = (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(128, kernel_size = (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dropout(rate = 0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nopt = optimizers.Adam(lr = 0.001)\nmodel.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])","execution_count":3,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = 32 #batch size\ntrain_y = pd.read_csv('../input/aerial-cactus-identification/train.csv', dtype = 'str')\ntrain_x = ImageDataGenerator(rescale = 1./255., validation_split = 0.15)\ntrain_generator = train_x.flow_from_dataframe(dataframe = train_y, directory = '../input/aerial-cactus-identification/train/train', x_col = \"id\", y_col = \"has_cactus\" ,subset = \"training\", target_size = (150, 150), batch_size = b, class_mode = 'binary', shuffle = True, color_mode = 'rgb')\nvalid_generator = train_x.flow_from_dataframe(dataframe = train_y, directory = '../input/aerial-cactus-identification/train/train', x_col = \"id\", y_col = \"has_cactus\", subset = \"validation\", target_size = (150, 150), batch_size = b, class_mode = 'binary', shuffle = True, color_mode = 'rgb')","execution_count":4,"outputs":[{"output_type":"stream","text":"Found 14875 images belonging to 2 classes.\nFound 2625 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x = ImageDataGenerator(rescale = 1./255.)\ntest_y = pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv', dtype = 'str')\ntest_generator = test_x.flow_from_dataframe(dataframe = test_y, directory = '../input/aerial-cactus-identification/test/test', x_col = \"id\", y_col = None, target_size = (150, 150), batch_size = b, class_mode = None, shuffle = False, color_mode = 'rgb')","execution_count":5,"outputs":[{"output_type":"stream","text":"Found 4000 images.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"steps_train = train_generator.n//train_generator.batch_size\nsteps_valid = valid_generator.n//valid_generator.batch_size\nsteps_test = test_generator.n//test_generator.batch_size\n\nh = model.fit_generator(generator = train_generator, steps_per_epoch = steps_train, validation_data = valid_generator, validation_steps = steps_valid, epochs = 10)","execution_count":6,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/10\n  2/464 [..............................] - ETA: 12:27 - loss: 0.6613 - acc: 0.4844","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-74328c23f274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msteps_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport json\nfrom tqdm import tqdm,tqdm_notebook\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":7,"outputs":[{"output_type":"stream","text":"['aerial-cactus-identification', 'resnett']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv(\"../input/aerial-cactus-identification/train.csv\")\ntrain_df[\"has_cactus\"]=train_df[\"has_cactus\"].map(lambda x:str(x))\nprint(train_df.shape)\n\nimport cv2\nimage=cv2.imread(\"../input/aerial-cactus-identification/train/train/01e30c0ba6e91343a12d2126fcafc0dd.jpg\"\n                )\nplt.imshow(image)\nprint(image.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"(17500, 2)\n(32, 32, 3)\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Train With ResNET-50**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Activation,Dropout,Flatten,Dense,MaxPooling2D\nfrom keras.applications import ResNet50\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras import regularizers","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model=ResNet50(weights=\"../input/resnett/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top=False,input_shape=(32,32,3))","execution_count":18,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_new_layer(base_model):\n    x=base_model.output\n    x=Flatten()(x)\n    x=Dense(512,activation=\"relu\")(x)\n    predictions = Dense(1, activation='sigmoid',activity_regularizer=regularizers.l1(0.05))(x)\n    model = Model(input=base_model.input, output=predictions)\n    return model\ndef transfer_learn(model, base_model):\n    for layer in base_model.layers:\n        layer.trainable = True\n    model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy',\n                  metrics=['accuracy'])","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen=ImageDataGenerator(rescale=1./255,\n                                 validation_split=0.1,\n                                 rotation_range=30,\n                                 shear_range=0.2,\n                                 horizontal_flip=True,\n                                 vertical_flip=True,\n                                 zoom_range=0.2)\ntrain_generator=train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"../input/aerial-cactus-identification/train/train\",\n    x_col=\"id\",\n    y_col=\"has_cactus\",\n    batch_size=32,\n    shuffle=True,\n    class_mode=\"binary\",\n    target_size=(32,32),\n    subset='training')\n\nvalidation_generator=train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"../input/aerial-cactus-identification/train/train\",\n    x_col=\"id\",\n    y_col=\"has_cactus\",\n    batch_size=32,\n    shuffle=True,\n    class_mode=\"binary\",\n    target_size=(32,32),\n    subset='validation')","execution_count":20,"outputs":[{"output_type":"stream","text":"Found 15750 images belonging to 2 classes.\nFound 1750 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=add_new_layer(base_model)","execution_count":21,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n  \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"transfer_learn(model, base_model)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit_generator(generator=train_generator,\n                            validation_data=validation_generator,\n                            validation_steps= 64,\n                            steps_per_epoch= 200,\n                            epochs=10,\n                            verbose=2)","execution_count":26,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-00e3d87dc1e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                             verbose=2)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}